sequenceDiagram
    participant U as üë§ Usu√°rio
    participant UI as üñ•Ô∏è Frontend
    participant API as üö™ API Gateway
    participant Chat as üí¨ Chat Service
    participant LF as üîÑ LangFlow
    participant Vec as üîç Vector DB
    participant LLM as ü§ñ Ollama/Llama
    participant DB as üì¶ SQLite/Postgres
    participant Cache as üöÄ Redis

    Note over U,Cache: Fluxo Principal - Chat com RAG

    U->>UI: Pergunta sobre documento
    UI->>API: POST /chat/message
    
    Note over API: Autentica√ß√£o & Rate Limiting
    API->>Chat: Processa mensagem
    
    Chat->>Cache: Verifica sess√£o ativa
    Cache-->>Chat: Dados da sess√£o
    
    Chat->>DB: Salva mensagem do usu√°rio
    DB-->>Chat: Message ID
    
    Chat->>LF: Executa RAG Pipeline
    
    Note over LF: Pipeline RAG Ativo
    LF->>LF: Gera embedding da query
    LF->>Vec: Busca documentos similares
    Vec-->>LF: Top-K documentos relevantes
    
    LF->>LF: Monta contexto + prompt
    LF->>LLM: Requisi√ß√£o com contexto
    
    Note over LLM: Processamento Local
    LLM-->>LF: Resposta gerada
    
    LF-->>Chat: Resposta final
    
    Chat->>DB: Salva resposta da IA
    Chat->>Cache: Atualiza contexto da sess√£o
    
    Chat-->>API: Resposta processada
    API-->>UI: JSON response
    UI-->>U: Exibe resposta

    Note over U,Cache: Fluxos Paralelos

    rect rgb(240, 248, 255)
        Note over Chat,Cache: Contexto de Atividades
        Chat->>DB: Busca hist√≥rico da atividade
        Chat->>Cache: Cache de contexto espec√≠fico
    end

    rect rgb(255, 248, 240)
        Note over LF,Vec: Ingest√£o de Documentos (Ass√≠ncrono)
        Note over LF: Quando novos docs chegam:
        LF->>LF: Chunking + Embedding
        LF->>Vec: Armazena vetores
    end

    rect rgb(248, 255, 248)
        Note over LLM: Otimiza√ß√µes Futuras
        Note over LLM: Load Balancing entre modelos
        Note over LLM: Cache de embeddings frequentes
    end